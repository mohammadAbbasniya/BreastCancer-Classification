{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BinaryClassification_Testing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zMNH3RI87S9e"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmdVvnMI7CcI"
      },
      "source": [
        "# Breast cancer detection using `Keras Applications` \n",
        "\n",
        "*    on [BreaKHis](https://web.inf.ufpr.br/vri/databases/breast-cancer-histopathological-database-breakhis) dataseet "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMNH3RI87S9e"
      },
      "source": [
        "## import libraries and connect to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4F-cAEZ8UKG"
      },
      "source": [
        "!pip install catboost\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML, display, clear_output\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, auc, roc_curve\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow.keras.applications as k_apps\n",
        "print(tf.version)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "size = (460,700)\n",
        "working_dir = 'drive/MyDrive/article-97'\n",
        "keras_apps = {\n",
        "    'VGG16'            : {'model': k_apps.vgg16.VGG16,'preprocessor': k_apps.vgg16.preprocess_input, 'activation': ''},\n",
        "    'VGG19'            : {'model': k_apps.vgg19.VGG19,'preprocessor': k_apps.vgg19.preprocess_input, 'activation': ''},\n",
        "\n",
        "    'ResNet50'         : {'model': k_apps.resnet50.ResNet50, 'preprocessor': k_apps.resnet.preprocess_input, 'activation': ''},\n",
        "    'ResNet101'        : {'model': k_apps.resnet.ResNet101, 'preprocessor': k_apps.resnet.preprocess_input, 'activation': ''},\n",
        "    'ResNet152'        : {'model': k_apps.resnet.ResNet152, 'preprocessor': k_apps.resnet.preprocess_input, 'activation': ''},\n",
        "    'ResNet50V2'       : {'model': k_apps.resnet_v2.ResNet50V2, 'preprocessor': k_apps.resnet_v2.preprocess_input, 'activation': ''},\n",
        "    'ResNet101V2'      : {'model': k_apps.resnet_v2.ResNet101V2, 'preprocessor': k_apps.resnet_v2.preprocess_input, 'activation': ''},\n",
        "    'ResNet152V2'      : {'model': k_apps.resnet_v2.ResNet152V2, 'preprocessor': k_apps.resnet_v2.preprocess_input, 'activation': ''},\n",
        "\n",
        "    'InceptionV3'      : {'model': k_apps.inception_v3.InceptionV3, 'preprocessor': k_apps.inception_v3.preprocess_input, 'activation': ''},\n",
        "    'InceptionResNetV2': {'model': k_apps.inception_resnet_v2.InceptionResNetV2, 'preprocessor': k_apps.inception_resnet_v2.preprocess_input, 'activation': 'conv_7b_ac'},\n",
        "\n",
        "    'DenseNet121'      : {'model': k_apps.densenet.DenseNet121, 'preprocessor': k_apps.densenet.preprocess_input, 'activation': ''},\n",
        "    'DenseNet169'      : {'model': k_apps.densenet.DenseNet169, 'preprocessor': k_apps.densenet.preprocess_input, 'activation': ''},\n",
        "    'DenseNet201'      : {'model': k_apps.densenet.DenseNet201, 'preprocessor': k_apps.densenet.preprocess_input, 'activation': ''},\n",
        "\n",
        "    'Xception'         : {'model': k_apps.xception.Xception, 'preprocessor': k_apps.xception.preprocess_input, 'activation': 'block14_sepconv2_act'},\n",
        "    'NASNetLarge'      : {'model': k_apps.nasnet.NASNetLarge, 'preprocessor': k_apps.nasnet.preprocess_input, 'activation': ''},\n",
        "\n",
        "    'EfficientNetV2M'  : {'model': k_apps.efficientnet_v2.EfficientNetV2M, 'preprocessor': k_apps.efficientnet_v2.preprocess_input, 'activation': ''},\n",
        "    'EfficientNetV2L'  : {'model': k_apps.efficientnet_v2.EfficientNetV2L, 'preprocessor': k_apps.efficientnet_v2.preprocess_input, 'activation': ''},\n",
        "    'EfficientNetB6'   : {'model': k_apps.efficientnet.EfficientNetB6, 'preprocessor': k_apps.efficientnet.preprocess_input, 'activation': ''},\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaEWsU3dnC8u"
      },
      "source": [
        "## Reading images and extracting features "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 0\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)\n",
        "\n",
        "featureExt =  \"EfficientNetB6\" #@param [\"VGG16\", \"VGG19\", \"ResNet50\", \"ResNet101\", \"ResNet152\", \"ResNet50V2\", \"ResNet101V2\", \"ResNet152V2\", \"InceptionV3\", \"InceptionResNetV2\", \"DenseNet121\",\"DenseNet169\",\"DenseNet201\", \"Xception\", \"NASNetLarge\",\"EfficientNetV2M\", \"EfficientNetV2L\", \"EfficientNetB6\"]\n",
        "magnification =  \"breast_400\" #@param [\"breast_40\", \"breast_100\", \"breast_200\", \"breast_400\"]\n",
        "extracting_mode = \"read pre-extracted features if exist\" #@param [\"read pre-extracted features if exist\", \"force to extract features now\"]\n",
        "\n",
        "# y1: Benign or Malignant (Two class classification)\n",
        "# y2: TA, PT, F, A, DC, PC, LC, MC (Eight class classification)\n",
        "# y3: Slide id (Pateint)\n",
        "X, y1, y2, y3 = [], [], [], []\n",
        "\n",
        "pre_extracted_file = f'{working_dir}/extracted_features/{featureExt}-{magnification}.txt'\n",
        "\n",
        "def read__tc_tt_id(path : 'str'):\n",
        "  '''\n",
        "  this mathod takes an image file full path\n",
        "  and returns the tumor_class, tumuor_type and slide_id\n",
        "  '''\n",
        "  f = path.split('/')[-1].split('-')\n",
        "  id = f[2]\n",
        "  f = f[0].split('_')\n",
        "  tt, tc= f[2], f[1]\n",
        "  return tc, tt, id\n",
        "\n",
        "\n",
        "def extract_features():\n",
        "  global X, y1, y2, y3\n",
        "  model = keras_apps[featureExt]['model'](input_shape=size+(3,), weights=None, pooling='max')\n",
        "  preprocess_input = keras_apps[featureExt]['preprocessor']\n",
        "  print(f'[start reading images and extracting features] \\nfeture extractor: {featureExt}, {model} \\npreprocessor    : {preprocess_input}\\n')\n",
        "\n",
        "  paths = glob.glob(f'{working_dir}/tf_files/{magnification}/*/*')\n",
        "\n",
        "  out = display(HTML(\"<progress style='width: 50%'/>\"), display_id=True)\n",
        "  n = len(paths)\n",
        "  for i in range(n):\n",
        "      img = image.load_img(str(paths[i]), target_size=size)\n",
        "      img = image.img_to_array(img)\n",
        "      img = preprocess_input(img) \n",
        "      img = np.expand_dims(img, axis=0)\n",
        "      features = model.predict(img)\n",
        "      tc, tt, id = read__tc_tt_id(paths[i])\n",
        "      X.append(features[0])\n",
        "      y1.append(tc)\n",
        "      y2.append(tt)\n",
        "      y3.append(id)\n",
        "      out.update(HTML(f\"[{i+1}/{n} images are processed] <br><progress value={i+1} max={n} , style='width: 60%'/></progress>  [{(i+1)/n*100:.2f}]%\"))\n",
        "\n",
        "  X = np.array(X)\n",
        "  le1, le2, le3 = LabelEncoder(), LabelEncoder(), LabelEncoder()\n",
        "  y1, y2, y3 = np.array(le1.fit_transform(y1)), np.array(le2.fit_transform(y2)), np.array(le3.fit_transform(y3))\n",
        "\n",
        "  #save etracted features\n",
        "  with open(pre_extracted_file, 'w') as f:\n",
        "    n, m = len(X), len(X[0])\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            f.write(str(X[i][j])+ ' ')\n",
        "        f.write(f'{y1[i]} {y2[i]} {y3[i]}\\n')\n",
        "\n",
        "\n",
        "if extracting_mode == \"read pre-extracted features if exist\": \n",
        "  if os.path.isfile(pre_extracted_file):\n",
        "    print('[pre-extracted features file was found] : ' + pre_extracted_file)\n",
        "    with open(pre_extracted_file , 'r') as f:\n",
        "      l = f.readline()\n",
        "      while l != '':\n",
        "          X.append([float(x) for x in l.split()])\n",
        "          l = f.readline()\n",
        "      X = np.array(X)\n",
        "      y1 = X[:, -3]\n",
        "      y2 = X[:, -2]\n",
        "      y3 = X[:, -1]\n",
        "      X = X[:, :-3]\n",
        "  else:\n",
        "    print('[pre-extracted features file NOT found]')\n",
        "    extract_features()\n",
        "else:\n",
        "  extract_features()\n",
        "  \n",
        "\n",
        "\n",
        "print(f'''\n",
        "[available data]:\n",
        "    - X : features matrix\n",
        "          shape {X.shape}\n",
        "    - y1: Binign/Malignant identifier \n",
        "          shape {y1.shape}\n",
        "    - y2: Tumour type (A, DC, F, LC, MC, PC, PT, TA) identifier \n",
        "          shape {y2.shape}\n",
        "    - y3: image slid id (patient id)\n",
        "          shape {y3.shape} \n",
        "''')"
      ],
      "metadata": {
        "id": "3Mq9Zyxtj_Mk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ],
      "metadata": {
        "id": "Jo1zHMOA5RZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_proba(y_test, p):\n",
        "  '''\n",
        "  this method takes y_test and list of probabilities\n",
        "  of each class provided by classifier.predict_proba.\n",
        "  Then returns the accuracy of that list in compare to\n",
        "  passed y_test using accuracy_score.\n",
        "  '''\n",
        "  y_pred = []\n",
        "  for r in p:\n",
        "    mx = 0\n",
        "    for i in range(len(r)):\n",
        "      if r[i] > r[mx]:\n",
        "        mx = i\n",
        "    y_pred.append(mx)\n",
        "  return accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "def eval(X, y, ctype:'str', clfs):\n",
        "  '''\n",
        "  This method evaluates the extracted features by three\n",
        "  classifiers which are tuned before and prints the accuracies\n",
        "  of predictions prepared by each classifier and the combination\n",
        "  of those classifiers. The random state used to split train and test.\n",
        "  '''\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = random_state)\n",
        "  probas = []\n",
        "  for c in clfs:\n",
        "    c.fit(X_train, y_train)\n",
        "    probas.append(c.predict_proba(X_test))\n",
        "\n",
        "  print(f'''\n",
        "  Feature extractor  : {featureExt}\n",
        "  Magnification      : {magnification}\n",
        "  Calssification type: {ctype}\n",
        "          {accuracy_proba(y_test, probas[0]) *100 :.4f}%  by XGBClassifier\n",
        "          {accuracy_proba(y_test, probas[1]) *100 :.4f}%  by LGBMClassifier\n",
        "          {accuracy_proba(y_test, probas[2]) *100 :.4f}%  by CatBoostClassifier\n",
        "          {accuracy_proba(y_test, probas[0]+probas[1]) *100 :.4f}%  by XGBClassifier  and LGBMClassifier\n",
        "          {accuracy_proba(y_test, probas[0]+probas[2]) *100 :.4f}%  by XGBClassifier  and CatBoostClassifier\n",
        "          {accuracy_proba(y_test, probas[1]+probas[2]) *100 :.4f}%  by LGBMClassifier and CatBoostClassifier\n",
        "          {accuracy_proba(y_test, probas[0]+probas[1]+probas[2]) *100 :.4f}%  by XGBClassifier  and LGBMClassifier and CatBoostClassifier\n",
        "  ''')"
      ],
      "metadata": {
        "id": "zj115Q9wsWFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Two Class Classification (Benign or Malignnat)"
      ],
      "metadata": {
        "id": "ctlBjaJAsYh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval(X, y1, rs, 'Tow-Class Classification', \n",
        "            [XGBClassifier(learning_rate = 0.34, silent = True),\n",
        "             LGBMClassifier(learning_rate = 0.11, silent = True),\n",
        "             CatBoostClassifier(l2_leaf_reg=3, border_count=128, iterations=1000, depth=7, logging_level='Silent')]) "
      ],
      "metadata": {
        "id": "9oDWWY8B8lvR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}